# -*- coding: utf-8 -*-
"""Review analaysis ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qeaISdg3uFiaZKxEgXh3XhUWH05OZdMG
"""

import pandas as pd
import numpy as np

df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSReNRzjhxq3oT03rISUM7-5UcNf_flKxO0AjFGcPbx3HapArOSyucjKEszeNDWUX7Qymiwm1Bqt73A/pub?gid=53846645&single=true&output=csv')

df.head()

X = df['review']

y = df['sentiment']

df.isnull().sum()

message = X.copy()

import spacy

"""**Language model**"""

nlp = spacy.load('en_core_web_sm')

corpus = []
empty_count = 0
import re

"""**Text Preprocessing**"""

for review in message:
  review = re.sub(r'<[^>]+>', ' ', review)
  review = re.sub('[^a-zA-Z]', ' ' , review) # Only take alphanumaric text
  review = review.lower() # always lower case
  review = nlp(review) # spacy object
  review = [token.lemma_ for token in review if not token.is_stop] #TOkenization lemmatization and removing stop word
  review = ' '.join(review)
  corpus.append(review) # add to courpus

print(empty_count)

from sklearn.feature_extraction.text import TfidfVectorizer

"""**Implemnting TF-IDF on courpus**"""

tv = TfidfVectorizer(max_features=50000) #Declearing TF-IDF
vector = tv.fit_transform(corpus) #TF-IDF of courpus

vector

y = df.iloc[:, 1].values

vector=vector.toarray()

vector

print("Any nonzero?", np.any(vector != 0))
print("Number of nonzero values:", np.count_nonzero(vector))
print("Example row nonzero count:", np.count_nonzero(vector[0]))

row_idx = 0
nonzero_indices = np.nonzero(vector[row_idx])[0]
print("Indices:", nonzero_indices)
print("Values:", vector[row_idx, nonzero_indices])

X = vector

"""**Splitting Dataset**"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
X, y, test_size=0.20, random_state=42)

"""**Initiating Naive Bayes**"""

from sklearn.naive_bayes import GaussianNB

gnb = GaussianNB() #initiating Gaussian naive Bayes

"""**Train Dataset Into Naive Bayes**"""

gnbmModel = gnb.fit(X_train,y_train)

"""**Prediction of Naive Bayes**"""

gnb_pred = gnbmModel.predict(X_test)

"""**Initiating Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier

DT = DecisionTreeClassifier() #initiate Decietion Tree

"""**Train Dataset into Decision Tree**"""

DTC = DT.fit(X_train,y_train)

"""**Prediction of Decition Tree**"""

DTC_pred = DTC.predict(X_test)

"""**Initiating Logisitic Regression**"""

from sklearn.linear_model import LogisticRegression

LR = LogisticRegression() #initiate Logistic Regression

"""**Train Daraset Into Logistic Regression**"""

LRModel = LR.fit(X_train,y_train)

"""**Prediction of Logistic Regression**"""

LRPredict = LRModel.predict(X_test)

"""**Confusion Matrix for Naive Bayes**"""

from sklearn.metrics import confusion_matrix
gnb_conf_matrix = confusion_matrix(y_test, gnb_pred)

print("Naieve Bayes Confusion Matrix:")
print(gnb_conf_matrix)

"""**Confusion Matrix for Decision Tree**"""

DT_conf_Matrix = confusion_matrix(y_test, DTC_pred)

print("Decision Tree Confusion Matrix:")
print(DT_conf_Matrix)

"""**Confusion Matrix for Logistic Regression**"""

LR_conf_Matrix = confusion_matrix(y_test, LRPredict)

print("Logistic Regression Confusion Matrix:")
print(LR_conf_Matrix)

import matplotlib.pyplot as plt
import seaborn as sns

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(gnb_conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Negative", "Positive"], yticklabels=["Negative", "Positive"])
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Naieve Bayes Confusion Matrix")
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(DT_conf_Matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Negative", "Positive"], yticklabels=["Negative", "Positive"])
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Decision Tree Confusion Matrix")
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(LR_conf_Matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Negative", "Positive"], yticklabels=["Negative", "Positive"])
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Logistic Regression Confusion Matrix")
plt.show()

from sklearn.metrics import accuracy_score, recall_score, f1_score

"""**Accuracy, Recall, F1-Score for Naive Bayes**"""

Gnb_accuracy = accuracy_score(y_test, gnb_pred)
Gnb_recall = recall_score(y_test, gnb_pred)
Gnb_f1 = f1_score(y_test, gnb_pred)

print(Gnb_accuracy)
print(Gnb_recall)
print(Gnb_f1)

"""**Accuracy, Recall, F1-Score for Decision Tree**"""

DT_accuracy = accuracy_score(y_test, DTC_pred)
DT_recall = recall_score(y_test, DTC_pred)
DT_f1 = f1_score(y_test, DTC_pred)

print(DT_accuracy)
print(DT_recall)
print(DT_f1)

"""**Accuracy, Recall, F1-Score for Logistic Regression**"""

LR_accuracy = accuracy_score(y_test, LRPredict)
LR_recall = recall_score(y_test, LRPredict)
LR_f1 = f1_score(y_test, LRPredict)

print(LR_accuracy)
print(LR_recall)
print(LR_f1)

"""**Classification of a test Instance**"""

X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(
    X, y, df.index, test_size=0.20, random_state=42
)

original_text = df.loc[idx_test[0], 'review']
original_label = df.loc[idx_test[0], 'sentiment']
print("Review Instance: ",original_text)
print("Review Label: ", original_label)
processed_text = corpus[idx_test[0]]  # processed text from corpus
print("Processed text:", processed_text)


GnbInstance = gnbmModel.predict(X_test[0].reshape(1, -1))
DTInstance = DTC.predict(X_test[0].reshape(1, -1))
LRInstance = LRModel.predict(X_test[0].reshape(1, -1))


print("Naieve Bayes Prediction: ",GnbInstance)
print("Decision Tree Prediction: ",DTInstance)
print("Logistic Regression Prediction: ",LRInstance)

import joblib
joblib.dump(gnbmModel, "Naive_Bayes_model.pkl")
joblib.dump(DTC, "Decision_Tree_model.pkl")
joblib.dump(LRModel, "Logistic_Regression_model.pkl")











